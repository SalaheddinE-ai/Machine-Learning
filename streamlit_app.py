import streamlit as st
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from datetime import datetime
import time

# Configuration de la page
st.set_page_config(
    page_title="Pr√©diction d'Esp√®ces de Manchots",
    page_icon="üêß",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #555;
        text-align: center;
        margin-bottom: 2rem;
    }
    .stMetric {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
    }
    .prediction-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 1rem;
        text-align: center;
        margin: 1rem 0;
    }
    .species-adelie { color: #FF6B6B; font-weight: bold; }
    .species-chinstrap { color: #4ECDC4; font-weight: bold; }
    .species-gentoo { color: #45B7D1; font-weight: bold; }
    </style>
""", unsafe_allow_html=True)

# Titre principal
st.markdown('<p class="main-header">ü§ñ Application de Machine Learning</p>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">Pr√©diction d\'esp√®ces de manchots avec Random Forest</p>', unsafe_allow_html=True)

# Fonction pour charger les donn√©es
@st.cache_data
def load_data():
    """Charge et pr√©pare les donn√©es des manchots"""
    try:
        df = pd.read_csv('https://raw.githubusercontent.com/dataprofessor/data/master/penguins_cleaned.csv')
        return df
    except Exception as e:
        st.error(f"Erreur lors du chargement des donn√©es : {e}")
        return None

# Dictionnaire des mod√®les de Machine Learning
ML_MODELS = {
    'Random Forest': {
        'model': RandomForestClassifier,
        'params': {
            'n_estimators': {'type': 'slider', 'min': 10, 'max': 500, 'default': 100, 'step': 10, 'label': 'Nombre d\'arbres'},
            'max_depth': {'type': 'slider', 'min': 1, 'max': 30, 'default': 10, 'step': 1, 'label': 'Profondeur maximale'},
            'min_samples_split': {'type': 'slider', 'min': 2, 'max': 20, 'default': 2, 'step': 1, 'label': 'Min √©chantillons pour split'}
        },
        'description': ' Ensemble d\'arbres de d√©cision. Robuste et performant pour la classification.',
    },
    'Gradient Boosting': {
        'model': GradientBoostingClassifier,
        'params': {
            'n_estimators': {'type': 'slider', 'min': 10, 'max': 300, 'default': 100, 'step': 10, 'label': 'Nombre d\'estimateurs'},
            'learning_rate': {'type': 'slider', 'min': 0.01, 'max': 1.0, 'default': 0.1, 'step': 0.01, 'label': 'Taux d\'apprentissage'},
            'max_depth': {'type': 'slider', 'min': 1, 'max': 10, 'default': 3, 'step': 1, 'label': 'Profondeur maximale'}
        },
        'description': ' Boosting s√©quentiel. Tr√®s performant mais plus lent √† entra√Æner.',
        
    },
    'Support Vector Machine': {
        'model': SVC,
        'params': {
            'C': {'type': 'slider', 'min': 0.01, 'max': 100.0, 'default': 1.0, 'step': 0.1, 'label': 'Param√®tre C (r√©gularisation)'},
            'kernel': {'type': 'selectbox', 'options': ['rbf', 'linear', 'poly', 'sigmoid'], 'default': 'rbf', 'label': 'Kernel'},
            'gamma': {'type': 'selectbox', 'options': ['scale', 'auto'], 'default': 'scale', 'label': 'Gamma'}
        },
        'description': ' Machine √† vecteurs de support. Excellent pour les donn√©es non-lin√©aires.',
        
    },
    'K-Nearest Neighbors': {
        'model': KNeighborsClassifier,
        'params': {
            'n_neighbors': {'type': 'slider', 'min': 1, 'max': 20, 'default': 5, 'step': 1, 'label': 'Nombre de voisins'},
            'weights': {'type': 'selectbox', 'options': ['uniform', 'distance'], 'default': 'uniform', 'label': 'Poids'},
            'metric': {'type': 'selectbox', 'options': ['euclidean', 'manhattan', 'minkowski'], 'default': 'euclidean', 'label': 'M√©trique'}
        },
        'description': ' Classification bas√©e sur la proximit√©. Simple et intuitif.',
        
    },
    'Decision Tree': {
        'model': DecisionTreeClassifier,
        'params': {
            'max_depth': {'type': 'slider', 'min': 1, 'max': 30, 'default': 10, 'step': 1, 'label': 'Profondeur maximale'},
            'min_samples_split': {'type': 'slider', 'min': 2, 'max': 20, 'default': 2, 'step': 1, 'label': 'Min √©chantillons pour split'},
            'criterion': {'type': 'selectbox', 'options': ['gini', 'entropy'], 'default': 'gini', 'label': 'Crit√®re de division'}
        },
        'description': ' Arbre de d√©cision unique. Facile √† interpr√©ter et visualiser.',
        
    },
    'Logistic Regression': {
        'model': LogisticRegression,
        'params': {
            'C': {'type': 'slider', 'min': 0.01, 'max': 100.0, 'default': 1.0, 'step': 0.1, 'label': 'Param√®tre C (r√©gularisation)'},
            'max_iter': {'type': 'slider', 'min': 100, 'max': 1000, 'default': 200, 'step': 100, 'label': 'It√©rations maximales'},
            'solver': {'type': 'selectbox', 'options': ['lbfgs', 'liblinear', 'saga'], 'default': 'lbfgs', 'label': 'Solveur'}
        },
        'description': ' R√©gression logistique. Simple, rapide et efficace pour la classification lin√©aire.',
        
    },
    'Naive Bayes': {
        'model': GaussianNB,
        'params': {
            'var_smoothing': {'type': 'slider', 'min': 1e-12, 'max': 1e-5, 'default': 1e-9, 'step': 1e-11, 'label': 'Lissage de variance', 'format': '%.2e'}
        },
        'description': ' Classificateur bay√©sien. Tr√®s rapide, id√©al pour les grands datasets.',
        
    },
   
    'AdaBoost': {
        'model': AdaBoostClassifier,
        'params': {
            'n_estimators': {'type': 'slider', 'min': 10, 'max': 300, 'default': 50, 'step': 10, 'label': 'Nombre d\'estimateurs'},
            'learning_rate': {'type': 'slider', 'min': 0.01, 'max': 2.0, 'default': 1.0, 'step': 0.1, 'label': 'Taux d\'apprentissage'}
        },
        'description': ' Adaptive Boosting. Combine des mod√®les faibles pour cr√©er un mod√®le fort.',
        
    }
}

# Fonction pour cr√©er un mod√®le avec ses param√®tres
def create_model(model_name, params):
    """Cr√©e une instance du mod√®le avec les param√®tres sp√©cifi√©s"""
    model_class = ML_MODELS[model_name]['model']
    
    # Param√®tres sp√©ciaux pour certains mod√®les
    if model_name == 'Support Vector Machine':
        params['probability'] = True  # N√©cessaire pour predict_proba
    elif model_name == 'Logistic Regression':
        params['multi_class'] = 'multinomial'
    elif model_name == 'Neural Network':
        params['max_iter'] = 500
        params['random_state'] = 42
    
    # Ajouter random_state si le mod√®le le supporte
    if model_name not in ['Naive Bayes', 'K-Nearest Neighbors']:
        params['random_state'] = 42
    
    return model_class(**params)

# Fonction pour l'encodage des donn√©es
def encode_data(df, encode_columns):
    """Encode les variables cat√©gorielles"""
    return pd.get_dummies(df, columns=encode_columns, prefix=encode_columns)

# Fonction pour entra√Æner le mod√®le
@st.cache_resource
def train_model(X, y, model_name, model_params):
    """Entra√Æne le mod√®le s√©lectionn√©"""
    # Division train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Cr√©er et entra√Æner le mod√®le
    start_time = time.time()
    clf = create_model(model_name, model_params)
    clf.fit(X_train, y_train)
    training_time = time.time() - start_time
    
    # √âvaluation
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    # Cross-validation score
    cv_scores = cross_val_score(clf, X_train, y_train, cv=5)
    cv_mean = cv_scores.mean()
    cv_std = cv_scores.std()
    
    return clf, accuracy, X_test, y_test, y_pred, training_time, cv_mean, cv_std

# Chargement des donn√©es
df = load_data()

if df is not None:
    # S√©paration X et y
    X_raw = df.drop('species', axis=1)
    y_raw = df['species']
    
    # Encodage de y
    target_mapper = {'Adelie': 0, 'Chinstrap': 1, 'Gentoo': 2}
    y = y_raw.map(target_mapper)
    
    # Encodage de X
    encode_columns = ['island', 'sex']
    X_encoded = encode_data(X_raw, encode_columns)
    
    # ========== SIDEBAR - PARAM√àTRES ==========
    with st.sidebar:
        st.header("ü§ñ S√©lection du Mod√®le")
        
        # S√©lection du mod√®le
        model_name = st.selectbox(
            'üéØ Choisir un mod√®le de ML',
            options=list(ML_MODELS.keys()),
            help="S√©lectionnez l'algorithme de Machine Learning √† utiliser"
        )
        
        # Afficher la description du mod√®le
        st.info(f"{ML_MODELS[model_name]['description']}")
        
        st.divider()
        st.header("‚öôÔ∏è Hyperparam√®tres")
        
        # G√©n√©rer dynamiquement les contr√¥les pour les param√®tres
        model_params = {}
        with st.expander("üîß Ajuster les param√®tres", expanded=True):
            for param_name, param_config in ML_MODELS[model_name]['params'].items():
                if param_config['type'] == 'slider':
                    format_str = param_config.get('format', None)
                    model_params[param_name] = st.slider(
                        param_config['label'],
                        min_value=param_config['min'],
                        max_value=param_config['max'],
                        value=param_config['default'],
                        step=param_config['step'],
                        format=format_str
                    )
                elif param_config['type'] == 'selectbox':
                    options = param_config['options']
                    default_idx = options.index(param_config['default']) if param_config['default'] in options else 0
                    model_params[param_name] = st.selectbox(
                        param_config['label'],
                        options=options,
                        index=default_idx
                    )
        
        st.divider()
        st.header("üìä Caract√©ristiques du Manchot")
        
        # Input features
        island = st.selectbox('√éle', ('Biscoe', 'Dream', 'Torgersen'))
        bill_length_mm = st.slider('Longueur du bec (mm)', 32.1, 59.6, 43.9)
        bill_depth_mm = st.slider('Profondeur du bec (mm)', 13.1, 21.5, 17.2)
        flipper_length_mm = st.slider('Longueur de la nageoire (mm)', 172.0, 231.0, 201.0)
        body_mass_g = st.slider(' Masse corporelle (g)', 2700.0, 6300.0, 4207.0)
        gender = st.selectbox('‚ö• Sexe', ('male', 'female'))
        
        # Info
        st.divider()
        st.info("üëÜ Ajustez les param√®tres ci-dessus puis consultez l'onglet **Pr√©diction**")
    
    # ========== ONGLETS PRINCIPAUX ==========
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üìà Pr√©diction", 
        "üìä Donn√©es", 
        "üìâ Visualisations", 
        "üéØ Performance du Mod√®le",
        "‚öñÔ∏è Comparaison des Mod√®les",
        "‚ÑπÔ∏è √Ä propos"
    ])
    
    # ========== TAB 1: PR√âDICTION ==========
    with tab1:
        st.header(" üßä Pr√©diction de l'Esp√®ce")
        
        # Cr√©er le DataFrame d'entr√©e
        input_data = {
            'island': island,
            'bill_length_mm': bill_length_mm,
            'bill_depth_mm': bill_depth_mm,
            'flipper_length_mm': flipper_length_mm,
            'body_mass_g': body_mass_g,
            'sex': gender
        }
        input_df = pd.DataFrame(input_data, index=[0])
        
        # Afficher les caract√©ristiques saisies
        st.subheader("üìù Caract√©ristiques saisies")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric(" √éle", island)
            st.metric(" Longueur du bec", f"{bill_length_mm} mm")
        with col2:
            st.metric("‚ö• Sexe", gender.capitalize())
            st.metric(" Profondeur du bec", f"{bill_depth_mm} mm")
        with col3:
            st.metric(" Longueur nageoire", f"{flipper_length_mm} mm")
            st.metric(" Masse corporelle", f"{body_mass_g} g")
        
        # Entra√Æner le mod√®le
        with st.spinner(f'ü§ñ Entra√Ænement du mod√®le {model_name} en cours...'):
            clf, accuracy, X_test, y_test, y_pred, training_time, cv_mean, cv_std = train_model(
                X_encoded, y, model_name, model_params
            )
        
        # Pr√©parer les donn√©es pour la pr√©diction
        input_penguins = pd.concat([input_df, X_raw], axis=0)
        input_encoded = encode_data(input_penguins, encode_columns)
        input_row = input_encoded[:1]
        
        # Assurer que toutes les colonnes sont pr√©sentes
        missing_cols = set(X_encoded.columns) - set(input_row.columns)
        for col in missing_cols:
            input_row[col] = 0
        input_row = input_row[X_encoded.columns]
        
        # Faire la pr√©diction
        prediction = clf.predict(input_row)
        prediction_proba = clf.predict_proba(input_row)
        
        # R√©sultats de pr√©diction
        st.divider()
        st.subheader("üéØ R√©sultats de la Pr√©diction")
        
        # Informations sur le mod√®le utilis√©
        st.info(f"**Mod√®le utilis√©**: {model_name}")
        
        species_names = ['Adelie', 'Chinstrap', 'Gentoo']
        predicted_species = species_names[prediction[0]]
        confidence = prediction_proba[0][prediction[0]] * 100
        
        # Affichage de la pr√©diction principale
        col1, col2 = st.columns([3, 1])
        
        with col1:
            species_class = f"species-{predicted_species.lower()}"
            st.markdown(f"""
            <div class="prediction-box">
                <h2>üêß Esp√®ce pr√©dite</h2>
                <h1 style="font-size: 3rem; margin: 1rem 0;">{predicted_species}</h1>
                <h3>Confiance : {confidence:.2f}%</h3>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"<div style='font-size: 120px; text-align: center; margin-top: 2rem;'>üêß</div>", 
                       unsafe_allow_html=True)
        
        # Tableau des probabilit√©s
        st.subheader("üìä Probabilit√©s par Esp√®ce")
        
        df_proba = pd.DataFrame({
            'Esp√®ce': species_names,
            'Probabilit√© (%)': [f"{p*100:.2f}%" for p in prediction_proba[0]],
            'Confiance': prediction_proba[0]
        })
        
        st.dataframe(
            df_proba,
            column_config={
                'Esp√®ce': st.column_config.TextColumn('üêß Esp√®ce', width='medium'),
                'Probabilit√© (%)': st.column_config.TextColumn('üìä Probabilit√©', width='medium'),
                'Confiance': st.column_config.ProgressColumn(
                    'üìà Niveau de confiance',
                    min_value=0,
                    max_value=1,
                    format="%.2f"
                )
            },
            hide_index=True,
            use_container_width=True
        )
        
        # Graphique avec bar_chart natif de Streamlit
        st.subheader("üìà Graphique de Probabilit√©s")
        chart_data = pd.DataFrame({
            'Probabilit√©': prediction_proba[0] * 100
        }, index=species_names)
        st.bar_chart(chart_data)
    
    # ========== TAB 2: DONN√âES ==========
    with tab2:
        st.header("üìä Exploration des Donn√©es")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üìù Observations", len(df))
        with col2:
            st.metric("üî¢ Variables", len(df.columns))
        with col3:
            st.metric("üêß Esp√®ces", df['species'].nunique())
        with col4:
            st.metric("‚úÖ Compl√©tude", "100%")
        
        st.divider()
        
        # Aper√ßu des donn√©es
        st.subheader("üëÄ Aper√ßu des Donn√©es Brutes")
        st.dataframe(df, use_container_width=True, height=400)
        
        # Statistiques descriptives
        with st.expander("üìà Statistiques Descriptives"):
            st.dataframe(df.describe(), use_container_width=True)
        
        # Distribution des esp√®ces
        st.subheader("üìä Distribution des Esp√®ces")
        species_counts = df['species'].value_counts()
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.bar_chart(species_counts)
        with col2:
            st.dataframe(
                pd.DataFrame({
                    'Esp√®ce': species_counts.index,
                    'Nombre': species_counts.values,
                    'Pourcentage': [f"{(v/len(df)*100):.1f}%" for v in species_counts.values]
                }),
                hide_index=True
            )
        
        # Informations par esp√®ce
        st.subheader("üìã R√©sum√© par Esp√®ce")
        for species in df['species'].unique():
            with st.expander(f"üêß {species}"):
                species_df = df[df['species'] == species]
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Nombre", len(species_df))
                with col2:
                    st.metric("Masse moyenne", f"{species_df['body_mass_g'].mean():.0f} g")
                with col3:
                    st.metric("Bec moyen", f"{species_df['bill_length_mm'].mean():.1f} mm")
    
    # ========== TAB 3: VISUALISATIONS ==========
    with tab3:
        st.header("üìâ Visualisations des Donn√©es")
        
        # Scatter plot avec Streamlit
        st.subheader("üîç Relation entre les Variables")
        
        col1, col2 = st.columns(2)
        with col1:
            x_axis = st.selectbox(
                'Axe X',
                ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'],
                index=0,
                key='x_axis'
            )
        with col2:
            y_axis = st.selectbox(
                'Axe Y',
                ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'],
                index=3,
                key='y_axis'
            )
        
        # Scatter chart natif Streamlit
        st.scatter_chart(
            data=df,
            x=x_axis,
            y=y_axis,
            color='species',
            size='body_mass_g'
        )
        
        # Distribution par variable
        st.subheader("üìä Distribution des Variables")
        
        variable = st.selectbox(
            'S√©lectionner une variable √† analyser',
            ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'],
            key='dist_var'
        )
        
        st.write(f"**Distribution de {variable.replace('_', ' ').title()}**")
        
        # Histogramme pour chaque esp√®ce
        for species in df['species'].unique():
            species_data = df[df['species'] == species][variable]
            st.write(f"**{species}**: Moyenne = {species_data.mean():.2f}, √âcart-type = {species_data.std():.2f}")
        
        # Comparaison avec line chart
        comparison_df = df.groupby('species')[variable].mean().reset_index()
        comparison_df.columns = ['Esp√®ce', 'Valeur Moyenne']
        st.bar_chart(comparison_df.set_index('Esp√®ce'))
        
        # Matrice de corr√©lation simplifi√©e
        st.subheader("üîó Corr√©lations entre Variables")
        numeric_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']
        corr_matrix = df[numeric_cols].corr().round(3)
        
        st.dataframe(
            corr_matrix,
            use_container_width=True,
            column_config={col: st.column_config.NumberColumn(
                col.replace('_', ' ').title(),
                format="%.3f"
            ) for col in corr_matrix.columns}
        )
        
        st.caption("üí° Les valeurs proches de 1 indiquent une forte corr√©lation positive, proche de -1 une forte corr√©lation n√©gative, et proche de 0 aucune corr√©lation.")
    
    # ========== TAB 4: PERFORMANCE ==========
    with tab4:
        st.header("üéØ Performance du Mod√®le")
        
        # M√©triques de performance
        st.subheader("üìä M√©triques Globales")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("üéØ Pr√©cision", f"{accuracy*100:.2f}%", 
                     delta=f"{(accuracy-0.8)*100:.1f}%" if accuracy > 0.8 else None)
        with col2:
            st.metric("üå≥ Arbres", model_params.get('n_estimators', 'N/A'))
        with col3:
            st.metric("üìè Profondeur", model_params.get('max_depth', 'N/A'))
        with col4:
            st.metric("‚öôÔ∏è Temps d'entra√Ænement", f"{training_time:.2f} sec")
        
        st.divider()
        
        # Matrice de confusion
        st.subheader("üî¢ Matrice de Confusion")
        cm = confusion_matrix(y_test, y_pred)
        
        cm_df = pd.DataFrame(
            cm,
            index=[f'R√©el: {s}' for s in species_names],
            columns=[f'Pr√©dit: {s}' for s in species_names]
        )
        
        st.dataframe(
            cm_df,
            use_container_width=True
        )
        
        # Rapport de classification
        st.subheader("üìã Rapport de Classification D√©taill√©")
        report = classification_report(
            y_test, 
            y_pred, 
            target_names=species_names,
            output_dict=True
        )
        
        report_df = pd.DataFrame(report).transpose()
        report_df = report_df.round(3)
        st.dataframe(
            report_df,
            use_container_width=True
        )
        
        # Feature importance (si disponible)
        st.subheader("üîç Importance des Variables")
        
        # V√©rifier si le mod√®le supporte feature_importances_
        if hasattr(clf, 'feature_importances_'):
            feature_importance = pd.DataFrame({
                'Variable': X_encoded.columns,
                'Importance': clf.feature_importances_
            }).sort_values('Importance', ascending=False).head(15)
            
            st.dataframe(
                feature_importance,
                column_config={
                    'Variable': st.column_config.TextColumn('üìä Variable', width='large'),
                    'Importance': st.column_config.ProgressColumn(
                        'üìà Importance',
                        min_value=0,
                        max_value=feature_importance['Importance'].max(),
                        format="%.4f"
                    )
                },
                hide_index=True,
                use_container_width=True
            )
            
            # Graphique d'importance
            st.bar_chart(feature_importance.set_index('Variable')['Importance'])
        elif hasattr(clf, 'coef_'):
            st.info("üìä Ce mod√®le utilise des coefficients au lieu d'importance de variables")
            # Afficher les coefficients pour les mod√®les lin√©aires
            coef_abs = np.abs(clf.coef_).mean(axis=0)
            feature_coef = pd.DataFrame({
                'Variable': X_encoded.columns,
                'Coefficient (abs)': coef_abs
            }).sort_values('Coefficient (abs)', ascending=False).head(15)
            
            st.dataframe(feature_coef, hide_index=True, use_container_width=True)
            st.bar_chart(feature_coef.set_index('Variable')['Coefficient (abs)'])
        else:
            st.warning("‚ö†Ô∏è Ce mod√®le ne fournit pas d'information sur l'importance des variables")
    
    # ========== TAB 5: COMPARAISON DES MOD√àLES ==========
    with tab5:
        st.header("üìä Comparaison des Mod√®les")
        
        st.info(" Cette section compare les performances de tous les mod√®les disponibles")
        
        if st.button(" Lancer la comparaison des mod√®les", type="primary"):
            comparison_results = []
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for idx, (m_name, m_config) in enumerate(ML_MODELS.items()):
                status_text.text(f"Entra√Ænement de {m_name}...")
                
                # Utiliser les param√®tres par d√©faut
                default_params = {}
                for param_name, param_config in m_config['params'].items():
                    default_params[param_name] = param_config['default']
                
                try:
                    # Entra√Æner le mod√®le
                    start = time.time()
                    model = create_model(m_name, default_params)
                    
                    X_train, X_test_temp, y_train, y_test_temp = train_test_split(
                        X_encoded, y, test_size=0.2, random_state=42, stratify=y
                    )
                    
                    model.fit(X_train, y_train)
                    train_time = time.time() - start
                    
                    # √âvaluer
                    y_pred_temp = model.predict(X_test_temp)
                    acc = accuracy_score(y_test_temp, y_pred_temp)
                    
                    # Cross-validation
                    cv_scores_temp = cross_val_score(model, X_train, y_train, cv=5)
                    
                    comparison_results.append({
                        'Mod√®le': m_name,
                        'Pr√©cision Test': f"{acc*100:.2f}%",
                        'Pr√©cision CV': f"{cv_scores_temp.mean()*100:.2f}%",
                        'CV Std': f"¬±{cv_scores_temp.std()*100:.2f}%",
                        'Temps (s)': f"{train_time:.3f}",
                        'Score': acc
                    })
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Erreur avec {m_name}: {str(e)}")
                
                progress_bar.progress((idx + 1) / len(ML_MODELS))
            
            status_text.text("‚úÖ Comparaison termin√©e!")
            
            # Afficher les r√©sultats
            if comparison_results:
                st.subheader("üèÜ R√©sultats de la Comparaison")
                
                comparison_df = pd.DataFrame(comparison_results)
                comparison_df = comparison_df.sort_values('Score', ascending=False)
                comparison_df = comparison_df.drop('Score', axis=1)
                
                # Ajouter des m√©dailles
                if len(comparison_df) >= 3:
                    comparison_df['Rang'] = ['ü•á', 'ü•à', 'ü•â'] + [''] * (len(comparison_df) - 3)
                    comparison_df = comparison_df[['Rang', 'Icon', 'Mod√®le', 'Pr√©cision Test', 'Pr√©cision CV', 'CV Std', 'Temps (s)']]
                
                st.dataframe(comparison_df, hide_index=True, use_container_width=True)
                
                # Conseils
                st.success(f"üèÜ **Meilleur mod√®le**: {comparison_df.iloc[0]['Mod√®le']} avec une pr√©cision de {comparison_df.iloc[0]['Pr√©cision Test']}")
                
                st.divider()
                st.subheader("üí° Conseils pour choisir un mod√®le")
                st.markdown("""
                - **Pr√©cision √©lev√©e** : Choisissez le mod√®le avec la meilleure pr√©cision test
                - **Rapidit√©** : Si le temps est important, privil√©giez les mod√®les rapides (Naive Bayes, Logistic Regression)
                - **Interpr√©tabilit√©** : Decision Tree et Logistic Regression sont plus faciles √† interpr√©ter
                - **Robustesse** : Random Forest et Gradient Boosting sont g√©n√©ralement plus robustes
                - **Donn√©es complexes** : Neural Network pour les relations non-lin√©aires complexes
                """)
        else:
            st.write("üëÜ Cliquez sur le bouton ci-dessus pour comparer tous les mod√®les")
            
            # Tableau r√©capitulatif des mod√®les
            st.subheader("üìã Mod√®les Disponibles")
            models_info = []
            for m_name, m_config in ML_MODELS.items():
                models_info.append({
                    'Mod√®le': m_name,
                    'Description': m_config['description']
                })
            
            models_df = pd.DataFrame(models_info)
            st.dataframe(models_df, hide_index=True, use_container_width=True)
    
    # ========== TAB 6: √Ä PROPOS ==========
    with tab6:
        st.header("‚ÑπÔ∏è √Ä propos de l'Application")
        
        st.markdown("""
        ### üêß Dataset des Manchots de Palmer
        
        Cette application utilise le c√©l√®bre dataset des manchots de Palmer pour d√©montrer 
        les capacit√©s du Machine Learning dans la classification d'esp√®ces.
        
        #### üìä Les Donn√©es
        - **Source**: Palmer Station, Antarctique
        - **Esp√®ces**: Adelie, Chinstrap, et Gentoo
        - **Variables**: Mesures morphologiques des manchots
        - **√éles**: Biscoe, Dream, et Torgersen
        
        #### ü§ñ Les Mod√®les Disponibles
        
        Cette application propose **9 algorithmes de Machine Learning** diff√©rents:
        
        1. ** Random Forest**: Ensemble d'arbres de d√©cision
        2. ** Gradient Boosting**: Boosting s√©quentiel puissant
        3. ** SVM**: Machine √† vecteurs de support
        4. ** K-Nearest Neighbors**: Classification par proximit√©
        5. ** Decision Tree**: Arbre de d√©cision simple
        6. ** Logistic Regression**: Classification lin√©aire
        7. ** Naive Bayes**: Classificateur bay√©sien
        8. ** AdaBoost**: Adaptive Boosting
        
        #### üéØ Caract√©ristiques de l'Application
        - ‚úÖ **8 mod√®les de ML** au choix
        - ‚úÖ **Hyperparam√®tres personnalisables** pour chaque mod√®le
        - ‚úÖ **Pr√©diction en temps r√©el**
        - ‚úÖ **Comparaison automatique** des mod√®les
        - ‚úÖ **Validation crois√©e** (5-fold CV)
        - ‚úÖ **M√©triques d√©taill√©es** (pr√©cision, matrice de confusion, rapport de classification)
        - ‚úÖ **Visualisations interactives** natives
        - ‚úÖ **Interface intuitive** et responsive
        
        #### üõ†Ô∏è Technologies Utilis√©es
        - **Streamlit**: Framework d'interface web
        - **Scikit-learn**: Biblioth√®que de Machine Learning
        - **Pandas**: Manipulation et analyse de donn√©es
        - **NumPy**: Calculs num√©riques
        
        #### üìà Comment utiliser l'application
        
        1. **Sidebar**: 
           - S√©lectionnez un mod√®le de ML
           - Ajustez ses hyperparam√®tres
           - D√©finissez les caract√©ristiques du manchot
        2. **Onglet Pr√©diction**: Visualisez la pr√©diction du mod√®le
        3. **Onglet Donn√©es**: Explorez le dataset
        4. **Onglet Visualisations**: Analysez les relations entre variables
        5. **Onglet Performance**: √âvaluez la qualit√© du mod√®le
        6. **Onglet Comparaison**: Comparez tous les mod√®les automatiquement
        
        #### üèÜ Conseils pour de Meilleures Pr√©dictions
        
        - **Random Forest** et **Gradient Boosting** offrent g√©n√©ralement les meilleures performances
        - **SVM** est excellent pour les donn√©es non-lin√©aires
        - **Logistic Regression** est rapide et simple pour d√©buter
        - Utilisez l'**onglet Comparaison** pour trouver le meilleur mod√®le
        
        #### üìö Ressources
        - [Dataset Palmer Penguins](https://github.com/allisonhorst/palmerpenguins)
        - [Documentation Streamlit](https://docs.streamlit.io)
        - [Documentation Scikit-learn](https://scikit-learn.org)
        - [Guide des algorithmes de classification](https://scikit-learn.org/stable/supervised_learning.html)
        
        #### üî¨ Variables du Dataset
        
        | Variable | Description | Unit√© |
        |----------|-------------|-------|
        | island | √éle o√π le manchot a √©t√© observ√© | Cat√©gorielle |
        | bill_length_mm | Longueur du bec | mm |
        | bill_depth_mm | Profondeur du bec | mm |
        | flipper_length_mm | Longueur de la nageoire | mm |
        | body_mass_g | Masse corporelle | g |
        | sex | Sexe du manchot | Cat√©gorielle |
        | species | Esp√®ce (cible) | Cat√©gorielle |
        
        ---
        
        üí° **Astuce**: Utilisez l'onglet "Comparaison des Mod√®les" pour identifier automatiquement 
        le meilleur algorithme pour ce dataset!
        
        ---
        
        D√©velopp√© avec ‚ù§Ô∏è pour l'apprentissage du Machine Learning
        """)
        
        # Informations syst√®me
        with st.expander("‚öôÔ∏è Informations Syst√®me"):
            st.code(f"""
üìÖ Date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

üìö Python Libraries:
- Streamlit: {st.__version__}
- Pandas: {pd.__version__}
- NumPy: {np.__version__}

ü§ñ Mod√®le Actuel: {model_name}
üéØ Pr√©cision: {accuracy*100:.2f}%
‚úÖ Pr√©cision CV: {cv_mean*100:.2f}% (¬±{cv_std*100:.2f}%)
‚è±Ô∏è Temps d'entra√Ænement: {training_time:.3f}s

üìä Dataset:
- Observations: {len(df)}
- Variables: {len(df.columns)}
- Esp√®ces: {df['species'].nunique()}

üîß Param√®tres:
{chr(10).join([f'- {k}: {v}' for k, v in model_params.items()])}
            """)
        
        # Exemples de pr√©diction
        with st.expander("üéÆ Exemples de Configuration"):
            st.markdown("""
            **Exemple 1 - Manchot Adelie typique:**
            - √éle: Torgersen
            - Longueur du bec: 39 mm
            - Profondeur du bec: 18 mm
            - Longueur nageoire: 190 mm
            - Masse: 3700 g
            
            **Exemple 2 - Manchot Gentoo typique:**
            - √éle: Biscoe
            - Longueur du bec: 47 mm
            - Profondeur du bec: 15 mm
            - Longueur nageoire: 217 mm
            - Masse: 5000 g
            
            **Exemple 3 - Manchot Chinstrap typique:**
            - √éle: Dream
            - Longueur du bec: 49 mm
            - Profondeur du bec: 18 mm
            - Longueur nageoire: 195 mm
            - Masse: 3800 g
            """)

else:
    st.error("‚ùå Impossible de charger les donn√©es. Veuillez v√©rifier votre connexion internet.")
    st.info("üí° Assurez-vous d'avoir une connexion internet active pour charger le dataset.")

# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: #666; padding: 1rem;'>
    <p>üêß <strong>Application de Machine Learning</strong> - Pr√©diction d'Esp√®ces de Manchots</p>
    <p>Cr√©√© avec Streamlit üòâ | ¬© 2025</p>
</div>
""", unsafe_allow_html=True)
