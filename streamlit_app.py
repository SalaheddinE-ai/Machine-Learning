import streamlit as st
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from datetime import datetime
import time

# Configuration de la page
st.set_page_config(
    page_title="PrÃ©diction d'EspÃ¨ces de Manchots",
    page_icon="ğŸ§",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalisÃ©
st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #555;
        text-align: center;
        margin-bottom: 2rem;
    }
    .stMetric {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
    }
    .prediction-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 1rem;
        text-align: center;
        margin: 1rem 0;
    }
    .species-adelie { color: #FF6B6B; font-weight: bold; }
    .species-chinstrap { color: #4ECDC4; font-weight: bold; }
    .species-gentoo { color: #45B7D1; font-weight: bold; }
    </style>
""", unsafe_allow_html=True)

# Titre principal
st.markdown('<p class="main-header">ğŸ§ Application de Machine Learning</p>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">PrÃ©diction d\'espÃ¨ces de manchots avec Random Forest</p>', unsafe_allow_html=True)

# Fonction pour charger les donnÃ©es
@st.cache_data
def load_data():
    """Charge et prÃ©pare les donnÃ©es des manchots"""
    try:
        df = pd.read_csv('https://raw.githubusercontent.com/dataprofessor/data/master/penguins_cleaned.csv')
        return df
    except Exception as e:
        st.error(f"Erreur lors du chargement des donnÃ©es : {e}")
        return None

# Dictionnaire des modÃ¨les de Machine Learning
ML_MODELS = {
    'Random Forest': {
        'model': RandomForestClassifier,
        'params': {
            'n_estimators': {'type': 'slider', 'min': 10, 'max': 500, 'default': 100, 'step': 10, 'label': 'Nombre d\'arbres'},
            'max_depth': {'type': 'slider', 'min': 1, 'max': 30, 'default': 10, 'step': 1, 'label': 'Profondeur maximale'},
            'min_samples_split': {'type': 'slider', 'min': 2, 'max': 20, 'default': 2, 'step': 1, 'label': 'Min Ã©chantillons pour split'}
        },
        'description': 'ğŸŒ³ Ensemble d\'arbres de dÃ©cision. Robuste et performant pour la classification.',
        'icon': 'ğŸŒ³'
    },
    'Gradient Boosting': {
        'model': GradientBoostingClassifier,
        'params': {
            'n_estimators': {'type': 'slider', 'min': 10, 'max': 300, 'default': 100, 'step': 10, 'label': 'Nombre d\'estimateurs'},
            'learning_rate': {'type': 'slider', 'min': 0.01, 'max': 1.0, 'default': 0.1, 'step': 0.01, 'label': 'Taux d\'apprentissage'},
            'max_depth': {'type': 'slider', 'min': 1, 'max': 10, 'default': 3, 'step': 1, 'label': 'Profondeur maximale'}
        },
        'description': 'ğŸš€ Boosting sÃ©quentiel. TrÃ¨s performant mais plus lent Ã  entraÃ®ner.',
        'icon': 'ğŸš€'
    },
    'Support Vector Machine': {
        'model': SVC,
        'params': {
            'C': {'type': 'slider', 'min': 0.01, 'max': 100.0, 'default': 1.0, 'step': 0.1, 'label': 'ParamÃ¨tre C (rÃ©gularisation)'},
            'kernel': {'type': 'selectbox', 'options': ['rbf', 'linear', 'poly', 'sigmoid'], 'default': 'rbf', 'label': 'Kernel'},
            'gamma': {'type': 'selectbox', 'options': ['scale', 'auto'], 'default': 'scale', 'label': 'Gamma'}
        },
        'description': 'ğŸ¯ Machine Ã  vecteurs de support. Excellent pour les donnÃ©es non-linÃ©aires.',
        'icon': 'ğŸ¯'
    },
    'K-Nearest Neighbors': {
        'model': KNeighborsClassifier,
        'params': {
            'n_neighbors': {'type': 'slider', 'min': 1, 'max': 20, 'default': 5, 'step': 1, 'label': 'Nombre de voisins'},
            'weights': {'type': 'selectbox', 'options': ['uniform', 'distance'], 'default': 'uniform', 'label': 'Poids'},
            'metric': {'type': 'selectbox', 'options': ['euclidean', 'manhattan', 'minkowski'], 'default': 'euclidean', 'label': 'MÃ©trique'}
        },
        'description': 'ğŸ‘¥ Classification basÃ©e sur la proximitÃ©. Simple et intuitif.',
        'icon': 'ğŸ‘¥'
    },
    'Decision Tree': {
        'model': DecisionTreeClassifier,
        'params': {
            'max_depth': {'type': 'slider', 'min': 1, 'max': 30, 'default': 10, 'step': 1, 'label': 'Profondeur maximale'},
            'min_samples_split': {'type': 'slider', 'min': 2, 'max': 20, 'default': 2, 'step': 1, 'label': 'Min Ã©chantillons pour split'},
            'criterion': {'type': 'selectbox', 'options': ['gini', 'entropy'], 'default': 'gini', 'label': 'CritÃ¨re de division'}
        },
        'description': 'ğŸŒ² Arbre de dÃ©cision unique. Facile Ã  interprÃ©ter et visualiser.',
        'icon': 'ğŸŒ²'
    },
    'Logistic Regression': {
        'model': LogisticRegression,
        'params': {
            'C': {'type': 'slider', 'min': 0.01, 'max': 100.0, 'default': 1.0, 'step': 0.1, 'label': 'ParamÃ¨tre C (rÃ©gularisation)'},
            'max_iter': {'type': 'slider', 'min': 100, 'max': 1000, 'default': 200, 'step': 100, 'label': 'ItÃ©rations maximales'},
            'solver': {'type': 'selectbox', 'options': ['lbfgs', 'liblinear', 'saga'], 'default': 'lbfgs', 'label': 'Solveur'}
        },
        'description': 'ğŸ“Š RÃ©gression logistique. Simple, rapide et efficace pour la classification linÃ©aire.',
        'icon': 'ğŸ“Š'
    },
    'Naive Bayes': {
        'model': GaussianNB,
        'params': {
            'var_smoothing': {'type': 'slider', 'min': 1e-12, 'max': 1e-5, 'default': 1e-9, 'step': 1e-11, 'label': 'Lissage de variance', 'format': '%.2e'}
        },
        'description': 'ğŸ² Classificateur bayÃ©sien. TrÃ¨s rapide, idÃ©al pour les grands datasets.',
        'icon': 'ğŸ²'
    },
    'Neural Network': {
        'model': MLPClassifier,
        'params': {
            'hidden_layer_sizes': {'type': 'selectbox', 'options': [(50,), (100,), (100, 50), (100, 100)], 'default': (100,), 'label': 'Architecture (couches cachÃ©es)'},
            'activation': {'type': 'selectbox', 'options': ['relu', 'tanh', 'logistic'], 'default': 'relu', 'label': 'Fonction d\'activation'},
            'learning_rate_init': {'type': 'slider', 'min': 0.0001, 'max': 0.1, 'default': 0.001, 'step': 0.0001, 'label': 'Taux d\'apprentissage', 'format': '%.4f'}
        },
        'description': 'ğŸ§  RÃ©seau de neurones. Puissant pour les relations complexes.',
        'icon': 'ğŸ§ '
    },
    'AdaBoost': {
        'model': AdaBoostClassifier,
        'params': {
            'n_estimators': {'type': 'slider', 'min': 10, 'max': 300, 'default': 50, 'step': 10, 'label': 'Nombre d\'estimateurs'},
            'learning_rate': {'type': 'slider', 'min': 0.01, 'max': 2.0, 'default': 1.0, 'step': 0.1, 'label': 'Taux d\'apprentissage'}
        },
        'description': 'âš¡ Adaptive Boosting. Combine des modÃ¨les faibles pour crÃ©er un modÃ¨le fort.',
        'icon': 'âš¡'
    }
}

# Fonction pour crÃ©er un modÃ¨le avec ses paramÃ¨tres
def create_model(model_name, params):
    """CrÃ©e une instance du modÃ¨le avec les paramÃ¨tres spÃ©cifiÃ©s"""
    model_class = ML_MODELS[model_name]['model']
    
    # ParamÃ¨tres spÃ©ciaux pour certains modÃ¨les
    if model_name == 'Support Vector Machine':
        params['probability'] = True  # NÃ©cessaire pour predict_proba
    elif model_name == 'Logistic Regression':
        params['multi_class'] = 'multinomial'
    elif model_name == 'Neural Network':
        params['max_iter'] = 500
        params['random_state'] = 42
    
    # Ajouter random_state si le modÃ¨le le supporte
    if model_name not in ['Naive Bayes', 'K-Nearest Neighbors']:
        params['random_state'] = 42
    
    return model_class(**params)

# Fonction pour l'encodage des donnÃ©es
def encode_data(df, encode_columns):
    """Encode les variables catÃ©gorielles"""
    return pd.get_dummies(df, columns=encode_columns, prefix=encode_columns)

# Fonction pour entraÃ®ner le modÃ¨le
@st.cache_resource
def train_model(X, y, model_name, model_params):
    """EntraÃ®ne le modÃ¨le sÃ©lectionnÃ©"""
    # Division train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # CrÃ©er et entraÃ®ner le modÃ¨le
    start_time = time.time()
    clf = create_model(model_name, model_params)
    clf.fit(X_train, y_train)
    training_time = time.time() - start_time
    
    # Ã‰valuation
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    # Cross-validation score
    cv_scores = cross_val_score(clf, X_train, y_train, cv=5)
    cv_mean = cv_scores.mean()
    cv_std = cv_scores.std()
    
    return clf, accuracy, X_test, y_test, y_pred, training_time, cv_mean, cv_std

# Chargement des donnÃ©es
df = load_data()

if df is not None:
    # SÃ©paration X et y
    X_raw = df.drop('species', axis=1)
    y_raw = df['species']
    
    # Encodage de y
    target_mapper = {'Adelie': 0, 'Chinstrap': 1, 'Gentoo': 2}
    y = y_raw.map(target_mapper)
    
    # Encodage de X
    encode_columns = ['island', 'sex']
    X_encoded = encode_data(X_raw, encode_columns)
    
    # ========== SIDEBAR - PARAMÃˆTRES ==========
    with st.sidebar:
        st.header("ğŸ¤– SÃ©lection du ModÃ¨le")
        
        # SÃ©lection du modÃ¨le
        model_name = st.selectbox(
            'ğŸ¯ Choisir un modÃ¨le de ML',
            options=list(ML_MODELS.keys()),
            help="SÃ©lectionnez l'algorithme de Machine Learning Ã  utiliser"
        )
        
        # Afficher la description du modÃ¨le
        st.info(f"{ML_MODELS[model_name]['icon']} {ML_MODELS[model_name]['description']}")
        
        st.divider()
        st.header("âš™ï¸ HyperparamÃ¨tres")
        
        # GÃ©nÃ©rer dynamiquement les contrÃ´les pour les paramÃ¨tres
        model_params = {}
        with st.expander("ğŸ”§ Ajuster les paramÃ¨tres", expanded=True):
            for param_name, param_config in ML_MODELS[model_name]['params'].items():
                if param_config['type'] == 'slider':
                    format_str = param_config.get('format', None)
                    model_params[param_name] = st.slider(
                        param_config['label'],
                        min_value=param_config['min'],
                        max_value=param_config['max'],
                        value=param_config['default'],
                        step=param_config['step'],
                        format=format_str
                    )
                elif param_config['type'] == 'selectbox':
                    options = param_config['options']
                    default_idx = options.index(param_config['default']) if param_config['default'] in options else 0
                    model_params[param_name] = st.selectbox(
                        param_config['label'],
                        options=options,
                        index=default_idx
                    )
        
        st.divider()
        st.header("ğŸ“Š CaractÃ©ristiques du Manchot")
        
        # Input features
        island = st.selectbox('ğŸï¸ Ãle', ('Biscoe', 'Dream', 'Torgersen'))
        bill_length_mm = st.slider('ğŸ“ Longueur du bec (mm)', 32.1, 59.6, 43.9)
        bill_depth_mm = st.slider('ğŸ“ Profondeur du bec (mm)', 13.1, 21.5, 17.2)
        flipper_length_mm = st.slider('ğŸ¦… Longueur de la nageoire (mm)', 172.0, 231.0, 201.0)
        body_mass_g = st.slider('âš–ï¸ Masse corporelle (g)', 2700.0, 6300.0, 4207.0)
        gender = st.selectbox('âš¥ Sexe', ('male', 'female'))
        
        # Info
        st.divider()
        st.info("ğŸ‘† Ajustez les paramÃ¨tres ci-dessus puis consultez l'onglet **PrÃ©diction**")
    
    # ========== ONGLETS PRINCIPAUX ==========
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "ğŸ“ˆ PrÃ©diction", 
        "ğŸ“Š DonnÃ©es", 
        "ğŸ“‰ Visualisations", 
        "ğŸ¯ Performance du ModÃ¨le",
        "âš–ï¸ Comparaison des ModÃ¨les",
        "â„¹ï¸ Ã€ propos"
    ])
    
    # ========== TAB 1: PRÃ‰DICTION ==========
    with tab1:
        st.header("ğŸ”® PrÃ©diction de l'EspÃ¨ce")
        
        # CrÃ©er le DataFrame d'entrÃ©e
        input_data = {
            'island': island,
            'bill_length_mm': bill_length_mm,
            'bill_depth_mm': bill_depth_mm,
            'flipper_length_mm': flipper_length_mm,
            'body_mass_g': body_mass_g,
            'sex': gender
        }
        input_df = pd.DataFrame(input_data, index=[0])
        
        # Afficher les caractÃ©ristiques saisies
        st.subheader("ğŸ“ CaractÃ©ristiques saisies")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ğŸï¸ Ãle", island)
            st.metric("ğŸ“ Longueur du bec", f"{bill_length_mm} mm")
        with col2:
            st.metric("âš¥ Sexe", gender.capitalize())
            st.metric("ğŸ“ Profondeur du bec", f"{bill_depth_mm} mm")
        with col3:
            st.metric("ğŸ¦… Longueur nageoire", f"{flipper_length_mm} mm")
            st.metric("âš–ï¸ Masse corporelle", f"{body_mass_g} g")
        
        # EntraÃ®ner le modÃ¨le
        with st.spinner(f'ğŸ¤– EntraÃ®nement du modÃ¨le {model_name} en cours...'):
            clf, accuracy, X_test, y_test, y_pred, training_time, cv_mean, cv_std = train_model(
                X_encoded, y, model_name, model_params
            )
        
        # PrÃ©parer les donnÃ©es pour la prÃ©diction
        input_penguins = pd.concat([input_df, X_raw], axis=0)
        input_encoded = encode_data(input_penguins, encode_columns)
        input_row = input_encoded[:1]
        
        # Assurer que toutes les colonnes sont prÃ©sentes
        missing_cols = set(X_encoded.columns) - set(input_row.columns)
        for col in missing_cols:
            input_row[col] = 0
        input_row = input_row[X_encoded.columns]
        
        # Faire la prÃ©diction
        prediction = clf.predict(input_row)
        prediction_proba = clf.predict_proba(input_row)
        
        # RÃ©sultats de prÃ©diction
        st.divider()
        st.subheader("ğŸ¯ RÃ©sultats de la PrÃ©diction")
        
        # Informations sur le modÃ¨le utilisÃ©
        st.info(f"**ModÃ¨le utilisÃ©**: {ML_MODELS[model_name]['icon']} {model_name}")
        
        species_names = ['Adelie', 'Chinstrap', 'Gentoo']
        predicted_species = species_names[prediction[0]]
        confidence = prediction_proba[0][prediction[0]] * 100
        
        # Affichage de la prÃ©diction principale
        col1, col2 = st.columns([3, 1])
        
        with col1:
            species_class = f"species-{predicted_species.lower()}"
            st.markdown(f"""
            <div class="prediction-box">
                <h2>ğŸ§ EspÃ¨ce prÃ©dite</h2>
                <h1 style="font-size: 3rem; margin: 1rem 0;">{predicted_species}</h1>
                <h3>Confiance : {confidence:.2f}%</h3>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"<div style='font-size: 120px; text-align: center; margin-top: 2rem;'>ğŸ§</div>", 
                       unsafe_allow_html=True)
        
        # Tableau des probabilitÃ©s
        st.subheader("ğŸ“Š ProbabilitÃ©s par EspÃ¨ce")
        
        df_proba = pd.DataFrame({
            'EspÃ¨ce': species_names,
            'ProbabilitÃ© (%)': [f"{p*100:.2f}%" for p in prediction_proba[0]],
            'Confiance': prediction_proba[0]
        })
        
        st.dataframe(
            df_proba,
            column_config={
                'EspÃ¨ce': st.column_config.TextColumn('ğŸ§ EspÃ¨ce', width='medium'),
                'ProbabilitÃ© (%)': st.column_config.TextColumn('ğŸ“Š ProbabilitÃ©', width='medium'),
                'Confiance': st.column_config.ProgressColumn(
                    'ğŸ“ˆ Niveau de confiance',
                    min_value=0,
                    max_value=1,
                    format="%.2f"
                )
            },
            hide_index=True,
            use_container_width=True
        )
        
        # Graphique avec bar_chart natif de Streamlit
        st.subheader("ğŸ“ˆ Graphique de ProbabilitÃ©s")
        chart_data = pd.DataFrame({
            'ProbabilitÃ©': prediction_proba[0] * 100
        }, index=species_names)
        st.bar_chart(chart_data)
    
    # ========== TAB 2: DONNÃ‰ES ==========
    with tab2:
        st.header("ğŸ“Š Exploration des DonnÃ©es")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“ Observations", len(df))
        with col2:
            st.metric("ğŸ”¢ Variables", len(df.columns))
        with col3:
            st.metric("ğŸ§ EspÃ¨ces", df['species'].nunique())
        with col4:
            st.metric("âœ… ComplÃ©tude", "100%")
        
        st.divider()
        
        # AperÃ§u des donnÃ©es
        st.subheader("ğŸ‘€ AperÃ§u des DonnÃ©es Brutes")
        st.dataframe(df, use_container_width=True, height=400)
        
        # Statistiques descriptives
        with st.expander("ğŸ“ˆ Statistiques Descriptives"):
            st.dataframe(df.describe(), use_container_width=True)
        
        # Distribution des espÃ¨ces
        st.subheader("ğŸ“Š Distribution des EspÃ¨ces")
        species_counts = df['species'].value_counts()
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.bar_chart(species_counts)
        with col2:
            st.dataframe(
                pd.DataFrame({
                    'EspÃ¨ce': species_counts.index,
                    'Nombre': species_counts.values,
                    'Pourcentage': [f"{(v/len(df)*100):.1f}%" for v in species_counts.values]
                }),
                hide_index=True
            )
        
        # Informations par espÃ¨ce
        st.subheader("ğŸ“‹ RÃ©sumÃ© par EspÃ¨ce")
        for species in df['species'].unique():
            with st.expander(f"ğŸ§ {species}"):
                species_df = df[df['species'] == species]
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Nombre", len(species_df))
                with col2:
                    st.metric("Masse moyenne", f"{species_df['body_mass_g'].mean():.0f} g")
                with col3:
                    st.metric("Bec moyen", f"{species_df['bill_length_mm'].mean():.1f} mm")
    
    # ========== TAB 3: VISUALISATIONS ==========
    with tab3:
        st.header("ğŸ“‰ Visualisations des DonnÃ©es")
        
        # Scatter plot avec Streamlit
        st.subheader("ğŸ” Relation entre les Variables")
        
        col1, col2 = st.columns(2)
        with col1:
            x_axis = st.selectbox(
                'Axe X',
                ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'],
                index=0,
                key='x_axis'
            )
        with col2:
            y_axis = st.selectbox(
                'Axe Y',
                ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'],
                index=3,
                key='y_axis'
            )
        
        # Scatter chart natif Streamlit
        st.scatter_chart(
            data=df,
            x=x_axis,
            y=y_axis,
            color='species',
            size='body_mass_g'
        )
        
        # Distribution par variable
        st.subheader("ğŸ“Š Distribution des Variables")
        
        variable = st.selectbox(
            'SÃ©lectionner une variable Ã  analyser',
            ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'],
            key='dist_var'
        )
        
        st.write(f"**Distribution de {variable.replace('_', ' ').title()}**")
        
        # Histogramme pour chaque espÃ¨ce
        for species in df['species'].unique():
            species_data = df[df['species'] == species][variable]
            st.write(f"**{species}**: Moyenne = {species_data.mean():.2f}, Ã‰cart-type = {species_data.std():.2f}")
        
        # Comparaison avec line chart
        comparison_df = df.groupby('species')[variable].mean().reset_index()
        comparison_df.columns = ['EspÃ¨ce', 'Valeur Moyenne']
        st.bar_chart(comparison_df.set_index('EspÃ¨ce'))
        
        # Matrice de corrÃ©lation simplifiÃ©e
        st.subheader("ğŸ”— CorrÃ©lations entre Variables")
        numeric_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']
        corr_matrix = df[numeric_cols].corr().round(3)
        
        st.dataframe(
            corr_matrix,
            use_container_width=True,
            column_config={col: st.column_config.NumberColumn(
                col.replace('_', ' ').title(),
                format="%.3f"
            ) for col in corr_matrix.columns}
        )
        
        st.caption("ğŸ’¡ Les valeurs proches de 1 indiquent une forte corrÃ©lation positive, proche de -1 une forte corrÃ©lation nÃ©gative, et proche de 0 aucune corrÃ©lation.")
    
    # ========== TAB 4: PERFORMANCE ==========
    with tab4:
        st.header("ğŸ¯ Performance du ModÃ¨le")
        
        # MÃ©triques de performance
        st.subheader("ğŸ“Š MÃ©triques Globales")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ¯ PrÃ©cision", f"{accuracy*100:.2f}%", 
                     delta=f"{(accuracy-0.8)*100:.1f}%" if accuracy > 0.8 else None)
        with col2:
            st.metric("ğŸŒ³ Arbres", model_params.get('n_estimators', 'N/A'))
        with col3:
            st.metric("ğŸ“ Profondeur", model_params.get('max_depth', 'N/A'))
        with col4:
            st.metric("âš™ï¸ Temps d'entraÃ®nement", f"{training_time:.2f} sec")
        
        st.divider()
        
        # Matrice de confusion
        st.subheader("ğŸ”¢ Matrice de Confusion")
        cm = confusion_matrix(y_test, y_pred)
        
        cm_df = pd.DataFrame(
            cm,
            index=[f'RÃ©el: {s}' for s in species_names],
            columns=[f'PrÃ©dit: {s}' for s in species_names]
        )
        
        st.dataframe(
            cm_df,
            use_container_width=True
        )
        
        # Rapport de classification
        st.subheader("ğŸ“‹ Rapport de Classification DÃ©taillÃ©")
        report = classification_report(
            y_test, 
            y_pred, 
            target_names=species_names,
            output_dict=True
        )
        
        report_df = pd.DataFrame(report).transpose()
        report_df = report_df.round(3)
        st.dataframe(
            report_df,
            use_container_width=True
        )
        
        # Feature importance (si disponible)
        st.subheader("ğŸ” Importance des Variables")
        
        # VÃ©rifier si le modÃ¨le supporte feature_importances_
        if hasattr(clf, 'feature_importances_'):
            feature_importance = pd.DataFrame({
                'Variable': X_encoded.columns,
                'Importance': clf.feature_importances_
            }).sort_values('Importance', ascending=False).head(15)
            
            st.dataframe(
                feature_importance,
                column_config={
                    'Variable': st.column_config.TextColumn('ğŸ“Š Variable', width='large'),
                    'Importance': st.column_config.ProgressColumn(
                        'ğŸ“ˆ Importance',
                        min_value=0,
                        max_value=feature_importance['Importance'].max(),
                        format="%.4f"
                    )
                },
                hide_index=True,
                use_container_width=True
            )
            
            # Graphique d'importance
            st.bar_chart(feature_importance.set_index('Variable')['Importance'])
        elif hasattr(clf, 'coef_'):
            st.info("ğŸ“Š Ce modÃ¨le utilise des coefficients au lieu d'importance de variables")
            # Afficher les coefficients pour les modÃ¨les linÃ©aires
            coef_abs = np.abs(clf.coef_).mean(axis=0)
            feature_coef = pd.DataFrame({
                'Variable': X_encoded.columns,
                'Coefficient (abs)': coef_abs
            }).sort_values('Coefficient (abs)', ascending=False).head(15)
            
            st.dataframe(feature_coef, hide_index=True, use_container_width=True)
            st.bar_chart(feature_coef.set_index('Variable')['Coefficient (abs)'])
        else:
            st.warning("âš ï¸ Ce modÃ¨le ne fournit pas d'information sur l'importance des variables")
    
    # ========== TAB 5: COMPARAISON DES MODÃˆLES ==========
    with tab5:
        st.header("ğŸ“Š Comparaison des ModÃ¨les")
        
        st.info("ğŸ”„ Cette section compare les performances de tous les modÃ¨les disponibles")
        
        if st.button("ğŸš€ Lancer la comparaison des modÃ¨les", type="primary"):
            comparison_results = []
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            for idx, (m_name, m_config) in enumerate(ML_MODELS.items()):
                status_text.text(f"EntraÃ®nement de {m_name}...")
                
                # Utiliser les paramÃ¨tres par dÃ©faut
                default_params = {}
                for param_name, param_config in m_config['params'].items():
                    default_params[param_name] = param_config['default']
                
                try:
                    # EntraÃ®ner le modÃ¨le
                    start = time.time()
                    model = create_model(m_name, default_params)
                    
                    X_train, X_test_temp, y_train, y_test_temp = train_test_split(
                        X_encoded, y, test_size=0.2, random_state=42, stratify=y
                    )
                    
                    model.fit(X_train, y_train)
                    train_time = time.time() - start
                    
                    # Ã‰valuer
                    y_pred_temp = model.predict(X_test_temp)
                    acc = accuracy_score(y_test_temp, y_pred_temp)
                    
                    # Cross-validation
                    cv_scores_temp = cross_val_score(model, X_train, y_train, cv=5)
                    
                    comparison_results.append({
                        'ModÃ¨le': m_name,
                        'Icon': m_config['icon'],
                        'PrÃ©cision Test': f"{acc*100:.2f}%",
                        'PrÃ©cision CV': f"{cv_scores_temp.mean()*100:.2f}%",
                        'CV Std': f"Â±{cv_scores_temp.std()*100:.2f}%",
                        'Temps (s)': f"{train_time:.3f}",
                        'Score': acc
                    })
                except Exception as e:
                    st.warning(f"âš ï¸ Erreur avec {m_name}: {str(e)}")
                
                progress_bar.progress((idx + 1) / len(ML_MODELS))
            
            status_text.text("âœ… Comparaison terminÃ©e!")
            
            # Afficher les rÃ©sultats
            if comparison_results:
                st.subheader("ğŸ† RÃ©sultats de la Comparaison")
                
                comparison_df = pd.DataFrame(comparison_results)
                comparison_df = comparison_df.sort_values('Score', ascending=False)
                comparison_df = comparison_df.drop('Score', axis=1)
                
                # Ajouter des mÃ©dailles
                if len(comparison_df) >= 3:
                    comparison_df['Rang'] = ['ğŸ¥‡', 'ğŸ¥ˆ', 'ğŸ¥‰'] + [''] * (len(comparison_df) - 3)
                    comparison_df = comparison_df[['Rang', 'Icon', 'ModÃ¨le', 'PrÃ©cision Test', 'PrÃ©cision CV', 'CV Std', 'Temps (s)']]
                
                st.dataframe(comparison_df, hide_index=True, use_container_width=True)
                
                # Conseils
                st.success(f"ğŸ† **Meilleur modÃ¨le**: {comparison_df.iloc[0]['ModÃ¨le']} avec une prÃ©cision de {comparison_df.iloc[0]['PrÃ©cision Test']}")
                
                st.divider()
                st.subheader("ğŸ’¡ Conseils pour choisir un modÃ¨le")
                st.markdown("""
                - **PrÃ©cision Ã©levÃ©e** : Choisissez le modÃ¨le avec la meilleure prÃ©cision test
                - **RapiditÃ©** : Si le temps est important, privilÃ©giez les modÃ¨les rapides (Naive Bayes, Logistic Regression)
                - **InterprÃ©tabilitÃ©** : Decision Tree et Logistic Regression sont plus faciles Ã  interprÃ©ter
                - **Robustesse** : Random Forest et Gradient Boosting sont gÃ©nÃ©ralement plus robustes
                - **DonnÃ©es complexes** : Neural Network pour les relations non-linÃ©aires complexes
                """)
        else:
            st.write("ğŸ‘† Cliquez sur le bouton ci-dessus pour comparer tous les modÃ¨les")
            
            # Tableau rÃ©capitulatif des modÃ¨les
            st.subheader("ğŸ“‹ ModÃ¨les Disponibles")
            models_info = []
            for m_name, m_config in ML_MODELS.items():
                models_info.append({
                    'Icon': m_config['icon'],
                    'ModÃ¨le': m_name,
                    'Description': m_config['description']
                })
            
            models_df = pd.DataFrame(models_info)
            st.dataframe(models_df, hide_index=True, use_container_width=True)
    
    # ========== TAB 6: Ã€ PROPOS ==========
    with tab6:
        st.header("â„¹ï¸ Ã€ propos de l'Application")
        
        st.markdown("""
        ### ğŸ§ Dataset des Manchots de Palmer
        
        Cette application utilise le cÃ©lÃ¨bre dataset des manchots de Palmer pour dÃ©montrer 
        les capacitÃ©s du Machine Learning dans la classification d'espÃ¨ces.
        
        #### ğŸ“Š Les DonnÃ©es
        - **Source**: Palmer Station, Antarctique
        - **EspÃ¨ces**: Adelie, Chinstrap, et Gentoo
        - **Variables**: Mesures morphologiques des manchots
        - **Ãles**: Biscoe, Dream, et Torgersen
        
        #### ğŸ¤– Les ModÃ¨les Disponibles
        
        Cette application propose **9 algorithmes de Machine Learning** diffÃ©rents:
        
        1. **ğŸŒ³ Random Forest**: Ensemble d'arbres de dÃ©cision
        2. **ğŸš€ Gradient Boosting**: Boosting sÃ©quentiel puissant
        3. **ğŸ¯ SVM**: Machine Ã  vecteurs de support
        4. **ğŸ‘¥ K-Nearest Neighbors**: Classification par proximitÃ©
        5. **ğŸŒ² Decision Tree**: Arbre de dÃ©cision simple
        6. **ğŸ“Š Logistic Regression**: Classification linÃ©aire
        7. **ğŸ² Naive Bayes**: Classificateur bayÃ©sien
        8. **ğŸ§  Neural Network**: RÃ©seau de neurones multicouche
        9. **âš¡ AdaBoost**: Adaptive Boosting
        
        #### ğŸ¯ CaractÃ©ristiques de l'Application
        - âœ… **9 modÃ¨les de ML** au choix
        - âœ… **HyperparamÃ¨tres personnalisables** pour chaque modÃ¨le
        - âœ… **PrÃ©diction en temps rÃ©el**
        - âœ… **Comparaison automatique** des modÃ¨les
        - âœ… **Validation croisÃ©e** (5-fold CV)
        - âœ… **MÃ©triques dÃ©taillÃ©es** (prÃ©cision, matrice de confusion, rapport de classification)
        - âœ… **Visualisations interactives** natives
        - âœ… **Interface intuitive** et responsive
        
        #### ğŸ› ï¸ Technologies UtilisÃ©es
        - **Streamlit**: Framework d'interface web
        - **Scikit-learn**: BibliothÃ¨que de Machine Learning
        - **Pandas**: Manipulation et analyse de donnÃ©es
        - **NumPy**: Calculs numÃ©riques
        
        #### ğŸ“ˆ Comment utiliser l'application
        
        1. **Sidebar**: 
           - SÃ©lectionnez un modÃ¨le de ML
           - Ajustez ses hyperparamÃ¨tres
           - DÃ©finissez les caractÃ©ristiques du manchot
        2. **Onglet PrÃ©diction**: Visualisez la prÃ©diction du modÃ¨le
        3. **Onglet DonnÃ©es**: Explorez le dataset
        4. **Onglet Visualisations**: Analysez les relations entre variables
        5. **Onglet Performance**: Ã‰valuez la qualitÃ© du modÃ¨le
        6. **Onglet Comparaison**: Comparez tous les modÃ¨les automatiquement
        
        #### ğŸ† Conseils pour de Meilleures PrÃ©dictions
        
        - **Random Forest** et **Gradient Boosting** offrent gÃ©nÃ©ralement les meilleures performances
        - **SVM** est excellent pour les donnÃ©es non-linÃ©aires
        - **Logistic Regression** est rapide et simple pour dÃ©buter
        - **Neural Network** peut capturer des relations complexes mais nÃ©cessite plus de donnÃ©es
        - Utilisez l'**onglet Comparaison** pour trouver le meilleur modÃ¨le
        
        #### ğŸ“š Ressources
        - [Dataset Palmer Penguins](https://github.com/allisonhorst/palmerpenguins)
        - [Documentation Streamlit](https://docs.streamlit.io)
        - [Documentation Scikit-learn](https://scikit-learn.org)
        - [Guide des algorithmes de classification](https://scikit-learn.org/stable/supervised_learning.html)
        
        #### ğŸ”¬ Variables du Dataset
        
        | Variable | Description | UnitÃ© |
        |----------|-------------|-------|
        | island | Ãle oÃ¹ le manchot a Ã©tÃ© observÃ© | CatÃ©gorielle |
        | bill_length_mm | Longueur du bec | mm |
        | bill_depth_mm | Profondeur du bec | mm |
        | flipper_length_mm | Longueur de la nageoire | mm |
        | body_mass_g | Masse corporelle | g |
        | sex | Sexe du manchot | CatÃ©gorielle |
        | species | EspÃ¨ce (cible) | CatÃ©gorielle |
        
        ---
        
        ğŸ’¡ **Astuce**: Utilisez l'onglet "Comparaison des ModÃ¨les" pour identifier automatiquement 
        le meilleur algorithme pour ce dataset!
        
        ---
        
        DÃ©veloppÃ© avec â¤ï¸ pour l'apprentissage du Machine Learning
        """)
        
        # Informations systÃ¨me
        with st.expander("âš™ï¸ Informations SystÃ¨me"):
            st.code(f"""
ğŸ“… Date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

ğŸ“š Python Libraries:
- Streamlit: {st.__version__}
- Pandas: {pd.__version__}
- NumPy: {np.__version__}

ğŸ¤– ModÃ¨le Actuel: {model_name}
ğŸ¯ PrÃ©cision: {accuracy*100:.2f}%
âœ… PrÃ©cision CV: {cv_mean*100:.2f}% (Â±{cv_std*100:.2f}%)
â±ï¸ Temps d'entraÃ®nement: {training_time:.3f}s

ğŸ“Š Dataset:
- Observations: {len(df)}
- Variables: {len(df.columns)}
- EspÃ¨ces: {df['species'].nunique()}

ğŸ”§ ParamÃ¨tres:
{chr(10).join([f'- {k}: {v}' for k, v in model_params.items()])}
            """)
        
        # Exemples de prÃ©diction
        with st.expander("ğŸ® Exemples de Configuration"):
            st.markdown("""
            **Exemple 1 - Manchot Adelie typique:**
            - Ãle: Torgersen
            - Longueur du bec: 39 mm
            - Profondeur du bec: 18 mm
            - Longueur nageoire: 190 mm
            - Masse: 3700 g
            
            **Exemple 2 - Manchot Gentoo typique:**
            - Ãle: Biscoe
            - Longueur du bec: 47 mm
            - Profondeur du bec: 15 mm
            - Longueur nageoire: 217 mm
            - Masse: 5000 g
            
            **Exemple 3 - Manchot Chinstrap typique:**
            - Ãle: Dream
            - Longueur du bec: 49 mm
            - Profondeur du bec: 18 mm
            - Longueur nageoire: 195 mm
            - Masse: 3800 g
            """)

else:
    st.error("âŒ Impossible de charger les donnÃ©es. Veuillez vÃ©rifier votre connexion internet.")
    st.info("ğŸ’¡ Assurez-vous d'avoir une connexion internet active pour charger le dataset.")

# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: #666; padding: 1rem;'>
    <p>ğŸ§ <strong>Application de Machine Learning</strong> - PrÃ©diction d'EspÃ¨ces de Manchots</p>
    <p>CrÃ©Ã© avec Streamlit ğŸˆ | Â© 2024</p>
</div>
""", unsafe_allow_html=True)
