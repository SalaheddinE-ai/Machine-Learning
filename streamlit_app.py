import streamlit as st
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from datetime import datetime

# Configuration de la page
st.set_page_config(
    page_title="PrÃ©diction d'EspÃ¨ces de Manchots",
    page_icon="ğŸ§",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalisÃ©
st.markdown("""
    <style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #555;
        text-align: center;
        margin-bottom: 2rem;
    }
    .stMetric {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
    }
    .prediction-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 1rem;
        text-align: center;
        margin: 1rem 0;
    }
    .species-adelie { color: #FF6B6B; font-weight: bold; }
    .species-chinstrap { color: #4ECDC4; font-weight: bold; }
    .species-gentoo { color: #45B7D1; font-weight: bold; }
    </style>
""", unsafe_allow_html=True)

# Titre principal
st.markdown('<p class="main-header">ğŸ§ Application de Machine Learning</p>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">PrÃ©diction d\'espÃ¨ces de manchots avec Random Forest</p>', unsafe_allow_html=True)

# Fonction pour charger les donnÃ©es
@st.cache_data
def load_data():
    """Charge et prÃ©pare les donnÃ©es des manchots"""
    try:
        df = pd.read_csv('https://raw.githubusercontent.com/dataprofessor/data/master/penguins_cleaned.csv')
        return df
    except Exception as e:
        st.error(f"Erreur lors du chargement des donnÃ©es : {e}")
        return None

# Fonction pour l'encodage des donnÃ©es
def encode_data(df, encode_columns):
    """Encode les variables catÃ©gorielles"""
    return pd.get_dummies(df, columns=encode_columns, prefix=encode_columns)

# Fonction pour entraÃ®ner le modÃ¨le
@st.cache_resource
def train_model(X, y, n_estimators=100, max_depth=None, random_state=42):
    """EntraÃ®ne le modÃ¨le Random Forest"""
    # Division train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=random_state, stratify=y
    )
    
    # EntraÃ®nement du modÃ¨le
    clf = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=random_state,
        n_jobs=-1
    )
    clf.fit(X_train, y_train)
    
    # Ã‰valuation
    y_pred = clf.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    return clf, accuracy, X_test, y_test, y_pred

# Chargement des donnÃ©es
df = load_data()

if df is not None:
    # SÃ©paration X et y
    X_raw = df.drop('species', axis=1)
    y_raw = df['species']
    
    # Encodage de y
    target_mapper = {'Adelie': 0, 'Chinstrap': 1, 'Gentoo': 2}
    y = y_raw.map(target_mapper)
    
    # Encodage de X
    encode_columns = ['island', 'sex']
    X_encoded = encode_data(X_raw, encode_columns)
    
    # ========== SIDEBAR - PARAMÃˆTRES ==========
    with st.sidebar:
        st.header("âš™ï¸ Configuration du ModÃ¨le")
        
        # HyperparamÃ¨tres
        with st.expander("ğŸ”§ HyperparamÃ¨tres", expanded=False):
            n_estimators = st.slider('Nombre d\'arbres', 10, 500, 100, 10)
            max_depth = st.slider('Profondeur maximale', 1, 20, 10)
            random_state = st.number_input('Random State', 0, 100, 42)
        
        st.divider()
        st.header("ğŸ“Š CaractÃ©ristiques du Manchot")
        
        # Input features
        island = st.selectbox('ğŸï¸ Ãle', ('Biscoe', 'Dream', 'Torgersen'))
        bill_length_mm = st.slider('ğŸ“ Longueur du bec (mm)', 32.1, 59.6, 43.9)
        bill_depth_mm = st.slider('ğŸ“ Profondeur du bec (mm)', 13.1, 21.5, 17.2)
        flipper_length_mm = st.slider('ğŸ¦… Longueur de la nageoire (mm)', 172.0, 231.0, 201.0)
        body_mass_g = st.slider('âš–ï¸ Masse corporelle (g)', 2700.0, 6300.0, 4207.0)
        gender = st.selectbox('âš¥ Sexe', ('male', 'female'))
        
        # Info
        st.divider()
        st.info("ğŸ‘† Ajustez les paramÃ¨tres ci-dessus puis consultez l'onglet **PrÃ©diction**")
    
    # ========== ONGLETS PRINCIPAUX ==========
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ“ˆ PrÃ©diction", 
        "ğŸ“Š DonnÃ©es", 
        "ğŸ“‰ Visualisations", 
        "ğŸ¯ Performance du ModÃ¨le",
        "â„¹ï¸ Ã€ propos"
    ])
    
    # ========== TAB 1: PRÃ‰DICTION ==========
    with tab1:
        st.header("ğŸ”® PrÃ©diction de l'EspÃ¨ce")
        
        # CrÃ©er le DataFrame d'entrÃ©e
        input_data = {
            'island': island,
            'bill_length_mm': bill_length_mm,
            'bill_depth_mm': bill_depth_mm,
            'flipper_length_mm': flipper_length_mm,
            'body_mass_g': body_mass_g,
            'sex': gender
        }
        input_df = pd.DataFrame(input_data, index=[0])
        
        # Afficher les caractÃ©ristiques saisies
        st.subheader("ğŸ“ CaractÃ©ristiques saisies")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ğŸï¸ Ãle", island)
            st.metric("ğŸ“ Longueur du bec", f"{bill_length_mm} mm")
        with col2:
            st.metric("âš¥ Sexe", gender.capitalize())
            st.metric("ğŸ“ Profondeur du bec", f"{bill_depth_mm} mm")
        with col3:
            st.metric("ğŸ¦… Longueur nageoire", f"{flipper_length_mm} mm")
            st.metric("âš–ï¸ Masse corporelle", f"{body_mass_g} g")
        
        # EntraÃ®ner le modÃ¨le
        with st.spinner('ğŸ¤– EntraÃ®nement du modÃ¨le en cours...'):
            clf, accuracy, X_test, y_test, y_pred = train_model(
                X_encoded, y, n_estimators, max_depth, random_state
            )
        
        # PrÃ©parer les donnÃ©es pour la prÃ©diction
        input_penguins = pd.concat([input_df, X_raw], axis=0)
        input_encoded = encode_data(input_penguins, encode_columns)
        input_row = input_encoded[:1]
        
        # Assurer que toutes les colonnes sont prÃ©sentes
        missing_cols = set(X_encoded.columns) - set(input_row.columns)
        for col in missing_cols:
            input_row[col] = 0
        input_row = input_row[X_encoded.columns]
        
        # Faire la prÃ©diction
        prediction = clf.predict(input_row)
        prediction_proba = clf.predict_proba(input_row)
        
        # RÃ©sultats de prÃ©diction
        st.divider()
        st.subheader("ğŸ¯ RÃ©sultats de la PrÃ©diction")
        
        species_names = ['Adelie', 'Chinstrap', 'Gentoo']
        predicted_species = species_names[prediction[0]]
        confidence = prediction_proba[0][prediction[0]] * 100
        
        # Affichage de la prÃ©diction principale
        col1, col2 = st.columns([3, 1])
        
        with col1:
            species_class = f"species-{predicted_species.lower()}"
            st.markdown(f"""
            <div class="prediction-box">
                <h2>ğŸ§ EspÃ¨ce prÃ©dite</h2>
                <h1 style="font-size: 3rem; margin: 1rem 0;">{predicted_species}</h1>
                <h3>Confiance : {confidence:.2f}%</h3>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"<div style='font-size: 120px; text-align: center; margin-top: 2rem;'>ğŸ§</div>", 
                       unsafe_allow_html=True)
        
        # Tableau des probabilitÃ©s
        st.subheader("ğŸ“Š ProbabilitÃ©s par EspÃ¨ce")
        
        df_proba = pd.DataFrame({
            'EspÃ¨ce': species_names,
            'ProbabilitÃ© (%)': [f"{p*100:.2f}%" for p in prediction_proba[0]],
            'Confiance': prediction_proba[0]
        })
        
        st.dataframe(
            df_proba,
            column_config={
                'EspÃ¨ce': st.column_config.TextColumn('ğŸ§ EspÃ¨ce', width='medium'),
                'ProbabilitÃ© (%)': st.column_config.TextColumn('ğŸ“Š ProbabilitÃ©', width='medium'),
                'Confiance': st.column_config.ProgressColumn(
                    'ğŸ“ˆ Niveau de confiance',
                    min_value=0,
                    max_value=1,
                    format="%.2f"
                )
            },
            hide_index=True,
            use_container_width=True
        )
        
        # Graphique avec bar_chart natif de Streamlit
        st.subheader("ğŸ“ˆ Graphique de ProbabilitÃ©s")
        chart_data = pd.DataFrame({
            'ProbabilitÃ©': prediction_proba[0] * 100
        }, index=species_names)
        st.bar_chart(chart_data)
    
    # ========== TAB 2: DONNÃ‰ES ==========
    with tab2:
        st.header("ğŸ“Š Exploration des DonnÃ©es")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“ Observations", len(df))
        with col2:
            st.metric("ğŸ”¢ Variables", len(df.columns))
        with col3:
            st.metric("ğŸ§ EspÃ¨ces", df['species'].nunique())
        with col4:
            st.metric("âœ… ComplÃ©tude", "100%")
        
        st.divider()
        
        # AperÃ§u des donnÃ©es
        st.subheader("ğŸ‘€ AperÃ§u des DonnÃ©es Brutes")
        st.dataframe(df, use_container_width=True, height=400)
        
        # Statistiques descriptives
        with st.expander("ğŸ“ˆ Statistiques Descriptives"):
            st.dataframe(df.describe(), use_container_width=True)
        
        # Distribution des espÃ¨ces
        st.subheader("ğŸ“Š Distribution des EspÃ¨ces")
        species_counts = df['species'].value_counts()
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.bar_chart(species_counts)
        with col2:
            st.dataframe(
                pd.DataFrame({
                    'EspÃ¨ce': species_counts.index,
                    'Nombre': species_counts.values,
                    'Pourcentage': [f"{(v/len(df)*100):.1f}%" for v in species_counts.values]
                }),
                hide_index=True
            )
        
        # Informations par espÃ¨ce
        st.subheader("ğŸ“‹ RÃ©sumÃ© par EspÃ¨ce")
        for species in df['species'].unique():
            with st.expander(f"ğŸ§ {species}"):
                species_df = df[df['species'] == species]
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Nombre", len(species_df))
                with col2:
                    st.metric("Masse moyenne", f"{species_df['body_mass_g'].mean():.0f} g")
                with col3:
                    st.metric("Bec moyen", f"{species_df['bill_length_mm'].mean():.1f} mm")
    
    # ========== TAB 3: VISUALISATIONS ==========
    with tab3:
        st.header("ğŸ“‰ Visualisations des DonnÃ©es")
        
        # Scatter plot avec Streamlit
        st.subheader("ğŸ” Relation entre les Variables")
        
        col1, col2 = st.columns(2)
        with col1:
            x_axis = st.selectbox(
                'Axe X',
                ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'],
                index=0,
                key='x_axis'
            )
        with col2:
            y_axis = st.selectbox(
                'Axe Y',
                ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'],
                index=3,
                key='y_axis'
            )
        
        # Scatter chart natif Streamlit
        st.scatter_chart(
            data=df,
            x=x_axis,
            y=y_axis,
            color='species',
            size='body_mass_g'
        )
        
        # Distribution par variable
        st.subheader("ğŸ“Š Distribution des Variables")
        
        variable = st.selectbox(
            'SÃ©lectionner une variable Ã  analyser',
            ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g'],
            key='dist_var'
        )
        
        st.write(f"**Distribution de {variable.replace('_', ' ').title()}**")
        
        # Histogramme pour chaque espÃ¨ce
        for species in df['species'].unique():
            species_data = df[df['species'] == species][variable]
            st.write(f"**{species}**: Moyenne = {species_data.mean():.2f}, Ã‰cart-type = {species_data.std():.2f}")
        
        # Comparaison avec line chart
        comparison_df = df.groupby('species')[variable].mean().reset_index()
        comparison_df.columns = ['EspÃ¨ce', 'Valeur Moyenne']
        st.bar_chart(comparison_df.set_index('EspÃ¨ce'))
        
        # Matrice de corrÃ©lation simplifiÃ©e
        st.subheader("ğŸ”— CorrÃ©lations entre Variables")
        numeric_cols = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']
        corr_matrix = df[numeric_cols].corr()
        st.dataframe(
            corr_matrix.style.background_gradient(cmap='RdBu_r', vmin=-1, vmax=1),
            use_container_width=True
        )
    
    # ========== TAB 4: PERFORMANCE ==========
    with tab4:
        st.header("ğŸ¯ Performance du ModÃ¨le")
        
        # MÃ©triques de performance
        st.subheader("ğŸ“Š MÃ©triques Globales")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ¯ PrÃ©cision", f"{accuracy*100:.2f}%", 
                     delta=f"{(accuracy-0.8)*100:.1f}%" if accuracy > 0.8 else None)
        with col2:
            st.metric("ğŸŒ³ Arbres", n_estimators)
        with col3:
            st.metric("ğŸ“ Profondeur", max_depth)
        with col4:
            st.metric("ğŸ”¢ Random State", random_state)
        
        st.divider()
        
        # Matrice de confusion
        st.subheader("ğŸ”¢ Matrice de Confusion")
        cm = confusion_matrix(y_test, y_pred)
        
        cm_df = pd.DataFrame(
            cm,
            index=[f'RÃ©el: {s}' for s in species_names],
            columns=[f'PrÃ©dit: {s}' for s in species_names]
        )
        
        st.dataframe(
            cm_df.style.background_gradient(cmap='Blues'),
            use_container_width=True
        )
        
        # Rapport de classification
        st.subheader("ğŸ“‹ Rapport de Classification DÃ©taillÃ©")
        report = classification_report(
            y_test, 
            y_pred, 
            target_names=species_names,
            output_dict=True
        )
        
        report_df = pd.DataFrame(report).transpose()
        report_df = report_df.round(3)
        st.dataframe(
            report_df.style.background_gradient(cmap='Greens', subset=['precision', 'recall', 'f1-score']),
            use_container_width=True
        )
        
        # Feature importance
        st.subheader("ğŸ” Importance des Variables")
        
        feature_importance = pd.DataFrame({
            'Variable': X_encoded.columns,
            'Importance': clf.feature_importances_
        }).sort_values('Importance', ascending=False).head(15)
        
        st.dataframe(
            feature_importance,
            column_config={
                'Variable': st.column_config.TextColumn('ğŸ“Š Variable', width='large'),
                'Importance': st.column_config.ProgressColumn(
                    'ğŸ“ˆ Importance',
                    min_value=0,
                    max_value=feature_importance['Importance'].max(),
                    format="%.4f"
                )
            },
            hide_index=True,
            use_container_width=True
        )
        
        # Graphique d'importance
        st.bar_chart(feature_importance.set_index('Variable')['Importance'])
    
    # ========== TAB 5: Ã€ PROPOS ==========
    with tab5:
        st.header("â„¹ï¸ Ã€ propos de l'Application")
        
        st.markdown("""
        ### ğŸ§ Dataset des Manchots de Palmer
        
        Cette application utilise le cÃ©lÃ¨bre dataset des manchots de Palmer pour dÃ©montrer 
        les capacitÃ©s du Machine Learning dans la classification d'espÃ¨ces.
        
        #### ğŸ“Š Les DonnÃ©es
        - **Source**: Palmer Station, Antarctique
        - **EspÃ¨ces**: Adelie, Chinstrap, et Gentoo
        - **Variables**: Mesures morphologiques des manchots
        - **Ãles**: Biscoe, Dream, et Torgersen
        
        #### ğŸ¤– Le ModÃ¨le
        - **Algorithme**: Random Forest Classifier
        - **TÃ¢che**: Classification multi-classes (3 espÃ¨ces)
        - **Librairie**: scikit-learn
        - **EntraÃ®nement**: 80% des donnÃ©es
        - **Test**: 20% des donnÃ©es
        
        #### ğŸ¯ CaractÃ©ristiques de l'Application
        - âœ… PrÃ©diction en temps rÃ©el
        - âœ… Visualisations interactives natives
        - âœ… MÃ©triques de performance dÃ©taillÃ©es
        - âœ… HyperparamÃ¨tres ajustables
        - âœ… Interface intuitive et responsive
        - âœ… Cache intelligent pour les performances
        
        #### ğŸ› ï¸ Technologies UtilisÃ©es
        - **Streamlit**: Framework d'interface web
        - **Scikit-learn**: BibliothÃ¨que de Machine Learning
        - **Pandas**: Manipulation et analyse de donnÃ©es
        - **NumPy**: Calculs numÃ©riques
        
        #### ğŸ“ˆ Comment utiliser l'application
        
        1. **Sidebar**: Ajustez les caractÃ©ristiques du manchot
        2. **Onglet PrÃ©diction**: Visualisez la prÃ©diction du modÃ¨le
        3. **Onglet DonnÃ©es**: Explorez le dataset
        4. **Onglet Visualisations**: Analysez les relations entre variables
        5. **Onglet Performance**: Ã‰valuez la qualitÃ© du modÃ¨le
        
        #### ğŸ“š Ressources
        - [Dataset Palmer Penguins](https://github.com/allisonhorst/palmerpenguins)
        - [Documentation Streamlit](https://docs.streamlit.io)
        - [Documentation Scikit-learn](https://scikit-learn.org)
        - [Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
        
        #### ğŸ”¬ Variables du Dataset
        
        | Variable | Description | UnitÃ© |
        |----------|-------------|-------|
        | island | Ãle oÃ¹ le manchot a Ã©tÃ© observÃ© | CatÃ©gorielle |
        | bill_length_mm | Longueur du bec | mm |
        | bill_depth_mm | Profondeur du bec | mm |
        | flipper_length_mm | Longueur de la nageoire | mm |
        | body_mass_g | Masse corporelle | g |
        | sex | Sexe du manchot | CatÃ©gorielle |
        | species | EspÃ¨ce (cible) | CatÃ©gorielle |
        
        ---
        
        ğŸ’¡ **Conseil**: Essayez diffÃ©rentes combinaisons de paramÃ¨tres pour voir comment 
        le modÃ¨le rÃ©agit et amÃ©liore ses prÃ©dictions!
        
        ---
        
        DÃ©veloppÃ© avec â¤ï¸ pour l'apprentissage du Machine Learning
        """)
        
        # Informations systÃ¨me
        with st.expander("âš™ï¸ Informations SystÃ¨me"):
            st.code(f"""
ğŸ“… Date: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

ğŸ“š Python Libraries:
- Streamlit: {st.__version__}
- Pandas: {pd.__version__}
- NumPy: {np.__version__}

ğŸ¯ Configuration du ModÃ¨le:
- Arbres: {n_estimators}
- Profondeur max: {max_depth}
- Random state: {random_state}
- PrÃ©cision: {accuracy*100:.2f}%

ğŸ“Š Dataset:
- Observations: {len(df)}
- Variables: {len(df.columns)}
- EspÃ¨ces: {df['species'].nunique()}
            """)
        
        # Exemples de prÃ©diction
        with st.expander("ğŸ® Exemples de Configuration"):
            st.markdown("""
            **Exemple 1 - Manchot Adelie typique:**
            - Ãle: Torgersen
            - Longueur du bec: 39 mm
            - Profondeur du bec: 18 mm
            - Longueur nageoire: 190 mm
            - Masse: 3700 g
            
            **Exemple 2 - Manchot Gentoo typique:**
            - Ãle: Biscoe
            - Longueur du bec: 47 mm
            - Profondeur du bec: 15 mm
            - Longueur nageoire: 217 mm
            - Masse: 5000 g
            
            **Exemple 3 - Manchot Chinstrap typique:**
            - Ãle: Dream
            - Longueur du bec: 49 mm
            - Profondeur du bec: 18 mm
            - Longueur nageoire: 195 mm
            - Masse: 3800 g
            """)

else:
    st.error("âŒ Impossible de charger les donnÃ©es. Veuillez vÃ©rifier votre connexion internet.")
    st.info("ğŸ’¡ Assurez-vous d'avoir une connexion internet active pour charger le dataset.")

# Footer
st.divider()
st.markdown("""
<div style='text-align: center; color: #666; padding: 1rem;'>
    <p>ğŸ§ <strong>Application de Machine Learning</strong> - PrÃ©diction d'EspÃ¨ces de Manchots</p>
    <p>CrÃ©Ã© avec Streamlit ğŸˆ | Â© 2024</p>
</div>
""", unsafe_allow_html=True)
